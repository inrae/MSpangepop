"""
Author: Lucien Piat
Institution: INRAe
Project: PangenOak
"""

import os
import yaml
import subprocess
import sys
import json

# Check if we should expand sweeps (can be controlled by an environment variable)
EXPAND_SWEEPS = os.environ.get("EXPAND_SWEEPS", "true").lower() == "true"

if EXPAND_SWEEPS:
    # First, expand any parameter sweeps in the config
    result = subprocess.run([sys.executable, "workflow/scripts/expand_sweeps.py", 
                            ".config/masterconfig.yaml"], 
                           capture_output=True, text=True)
    print(result.stdout)
    if result.returncode != 0:
        print(f"❌ Error expanding sweeps: {result.stderr}", file=sys.stderr)
        sys.exit(1)
    
    # Use the expanded config if it exists
    if os.path.exists(".config/expanded_config.yaml"):
        configfile: ".config/expanded_config.yaml"
    else:
        configfile: ".config/masterconfig.yaml"
else:
    configfile: ".config/masterconfig.yaml"


output_dir = config.get("output_dir", "results/")
temp_dir= config.get("tempfile_location", "00_temp/")
plot_dir = "01_plots/"
simulation_data = "02_simulation_data/"
graph  = "03_graph/"

# Retrieve memory multiplier from config
memory_multiplier = config.get("memory_multiplier", 1)

# Create explicit targets
def get_all_targets():
    targets = []
    for sample in config["samples"].keys():
        chr_n = config["samples"][sample]["chr_n"]
        # Add polished GFA files
        for chr_num in range(1, chr_n + 1):
            targets.append(os.path.join(output_dir, sample, graph,f"chr_{chr_num}", f"{sample}_chr_{chr_num}_graph.gfa"))
            targets.append(os.path.join(output_dir, sample, plot_dir, f"chr_{chr_num}", "visualization_complete.txt"))
        # Add global recap
        targets.append(os.path.join(output_dir, sample, simulation_data, f"{sample}_global_recap.txt"))
    return targets

rule all:
    input: get_all_targets()

# This rule is used to create a recap file for the workflow
rule setup:
    input:
        configfile= ".config/masterconfig.yaml",
        fasta=lambda wildcards: config["samples"][wildcards.sample]["fasta_gz"]
    output:
        recap_file=os.path.join(output_dir, "{sample}", simulation_data, "{sample}_global_recap.txt"),
        fai=temp(os.path.join(output_dir, "{sample}", temp_dir, "{sample}_full.fai"))
    params:
        out=lambda wildcards: os.path.join(output_dir, wildcards.sample, simulation_data),
        chr_n =lambda wildcards: config["samples"][wildcards.sample]["chr_n"]
    resources:
        mem_mb=lambda wildcards: int(1000 * memory_multiplier),
        time="00:10:00"
    threads: 1
    container:
        "oras://registry.forge.inrae.fr/pangepop/mspangepop/msprime_box:latest"
    priority: 10
    shell:
        """
        python3 workflow/scripts/recap.py {input.configfile} \
            {params.out} \
            {wildcards.sample}
        python3 workflow/scripts/input_index.py --fasta_file {input.fasta} \
            --output_file {output.fai} \
            --min_contigs {params.chr_n}
        """

# Simulate the coalescent and save it to a json file
rule msprime_simulation:    
    input:
        fai=rules.setup.output.fai,
        demographic=lambda wildcards: config["samples"][wildcards.sample]["demographic_file"]
    output:
        json = temp(os.path.join(output_dir, "{sample}", temp_dir, "chr_{chromosome}", "{sample}_chr_{chromosome}_msprime_simulation.json")),
        mutated_ts = os.path.join(output_dir, "{sample}", simulation_data, "chr_{chromosome}", "{sample}_chr_{chromosome}_mutated_ts.trees"),
        ancestry_ts = os.path.join(output_dir, "{sample}", simulation_data, "chr_{chromosome}", "{sample}_chr_{chromosome}_ancestry_ts.trees"), 
        full_ancestry_ts = os.path.join(output_dir, "{sample}", simulation_data, "chr_{chromosome}", "{sample}_chr_{chromosome}_full_ancestry_ts.trees"), 
        recap = os.path.join(output_dir, "{sample}", simulation_data, "chr_{chromosome}", "{sample}_chr_{chromosome}_msprime_recap.txt"),
    params:
        model=lambda wildcards: config["samples"][wildcards.sample].get("model", "binary"), 
        readable_json=lambda wildcards: config["samples"][wildcards.sample].get("readable_json", False), 
        seed=lambda wildcards: config["samples"][wildcards.sample].get("seed", None)
    resources:
        mem_mb=lambda wildcards: int(200000 * memory_multiplier),
        time="60:00:00"
    threads: 1
    benchmark:
        os.path.join(output_dir, "{sample}", "benchmark", "chr_{chromosome}", "msprime_simulation_benchmark.txt")
    container:
        "oras://registry.forge.inrae.fr/pangepop/mspangepop/msprime_box:latest"
    priority: 10
    shell:
        """
        python3 workflow/scripts/msprime_simulation.py \
            -fai {input.fai} \
            -d {input.demographic} \
            -c {wildcards.chromosome} \
            -mo {params.model} \
            --readable_json {params.readable_json} \
            --seed {params.seed} \
            --mutated_ts {output.mutated_ts} \
            --ancestry_ts {output.ancestry_ts} \
            --full_ancestry_ts {output.full_ancestry_ts} \
            --json {output.json} \
            --recap {output.recap}
        """

rule visualization:
    input:
        mutated_ts = rules.msprime_simulation.output.mutated_ts,
        ancestry_ts = rules.msprime_simulation.output.ancestry_ts,
        full_ancestry_ts = rules.msprime_simulation.output.full_ancestry_ts
    output:
        completion_flag = os.path.join(output_dir, "{sample}", plot_dir, "chr_{chromosome}", "visualization_complete.txt")
    params:
        out_tree = lambda wc: os.path.join(
            output_dir, wc.sample, plot_dir, f"chr_{wc.chromosome}", "01_tree_plots"),
        out_arg = lambda wc: os.path.join(
            output_dir, wc.sample, plot_dir, f"chr_{wc.chromosome}", "02_arg_plots")
    resources:
        mem_mb=lambda wc: int(5000 * memory_multiplier),
        time="01:00:00"
    threads: 2  
    benchmark:
        os.path.join(output_dir, "{sample}", "benchmark", "chr_{chromosome}", "visualization.txt")
    container:
        "oras://registry.forge.inrae.fr/pangepop/mspangepop/msprime_box:latest"
    priority: 2
    shell:
        """
        python3 workflow/scripts/visualizer_tree.py {input.mutated_ts} \
            {input.ancestry_ts} \
            -o {params.out_tree} \
            -c {wildcards.chromosome} \
            --occasions 5 \
            --edge-width 4 &

        python3 workflow/scripts/visualizer_arg.py \
            {input.full_ancestry_ts} \
            {params.out_arg} \
            {wildcards.chromosome} &

        wait
        echo "Visualization completed at $(date)" > {output.completion_flag}
        """


# Use the preorder traversal to get the order in which the mutations should be handled, save a json
rule coalescent_traversal:
    input:
        json = rules.msprime_simulation.output.json
    output:
        traversal = temp(os.path.join(output_dir, "{sample}", temp_dir, "chr_{chromosome}", "{sample}_chr_{chromosome}_traversal.json"))
    params:
        readable_json=lambda wildcards: config["samples"][wildcards.sample].get("readable_json", False) 
    resources:
        mem_mb=lambda wildcards: int(50000 * memory_multiplier),
        time="10:00:00"
    threads: 10
    priority: 9
    group: "traversal_pipeline"
    benchmark:
        os.path.join(output_dir, "{sample}", "benchmark", "chr_{chromosome}", "coalescent_traversal_benchmark.txt")
    container:
        "oras://registry.forge.inrae.fr/pangepop/mspangepop/msprime_box:latest"
    shell: 
        """
        python3 workflow/scripts/coalescent_traversal.py --json {input.json} \
            --chromosome {wildcards.chromosome} \
            --output_file {output.traversal} \
            --threads {threads} \
            --readable_json {params.readable_json}
        """

# Split fasta file at each recombination event
rule split_recombination:
    input:
        json = rules.msprime_simulation.output.json,
        fasta=lambda wildcards: config["samples"][wildcards.sample]["fasta_gz"]
    output:
        split_fasta = os.path.join(output_dir, "{sample}", simulation_data, "chr_{chromosome}", "{sample}_chr_{chromosome}_recombinations.fasta.gz")
    resources:
        mem_mb=lambda wildcards: int(50000 * memory_multiplier),
        time="10:00:00"
    threads: 1
    benchmark:
        os.path.join(output_dir, "{sample}", "benchmark", "chr_{chromosome}", "split_recombination_benchmark.txt")
    priority: 8
    container:
        "oras://registry.forge.inrae.fr/pangepop/mspangepop/msprime_box:latest"
    shell:
        """
        python3 workflow/scripts/split_recombination.py --json {input.json} \
            --fasta {input.fasta} \
            --chromosome {wildcards.chromosome} \
            --output {output.split_fasta}
        """       

# Script to augment the traversal json file with mutations position type and length
rule draw_variants:
    input:
        traversal_json = rules.coalescent_traversal.output.traversal
    output:
        augmented_traversal = os.path.join(output_dir, "{sample}", graph, "chr_{chromosome}", "traversal", "{sample}_chr_{chromosome}_augmented_traversal.json")
    params:
        sv_distribution = lambda wildcards: json.dumps(config["samples"][wildcards.sample].get("sv_distribution")),
        minimal_sv_length = lambda wildcards: config["samples"][wildcards.sample].get("minimal_sv_length", 1),
        readable_json = lambda wildcards: config["samples"][wildcards.sample].get("readable_json", False), 
        seed=lambda wildcards: config["samples"][wildcards.sample].get("seed", None)
    threads: 10
    group: "traversal_pipeline"
    priority: 8
    resources:
        mem_mb=lambda wildcards: int(10000 * memory_multiplier),
        time="10:00:00"
    container:
        "oras://registry.forge.inrae.fr/pangepop/mspangepop/msprime_box:latest"
    benchmark:
        os.path.join(output_dir, "{sample}", "benchmark", "chr_{chromosome}", "draw_variants_benchmark.txt")
    shell:
        """
        python3 workflow/scripts/draw_variants.py \
            --json {input.traversal_json} \
            --sv_distribution '{params.sv_distribution}' \
            --output {output.augmented_traversal} \
            --chromosome {wildcards.chromosome} \
            --threads {threads} \
            --minimal_sv_length {params.minimal_sv_length} \
            --readable_json {params.readable_json} \
            --seed {params.seed} 
        """

# Create the graph from the augmented traversal (headache inducing script)
rule graph_creation:
    input:
        split_fasta=rules.split_recombination.output.split_fasta,
        augmented_traversal = rules.draw_variants.output.augmented_traversal,
    output:
        gfa = temp(os.path.join(output_dir, "{sample}", temp_dir, "{sample}_chr_{chromosome}_unmergeg_graph.gfa")),
        recap = os.path.join(output_dir, "{sample}", simulation_data, "chr_{chromosome}","{sample}_chr_{chromosome}_graph_creation_recap.txt")
    params:
        out_dir = lambda wildcards: os.path.join(output_dir, wildcards.sample, plot_dir, f"chr_{wildcards.chromosome}", "03_graph_plots"), 
        fasta_folder = lambda wildcards: os.path.join(output_dir, wildcards.sample, graph,  f"chr_{wildcards.chromosome}", "fasta")
    resources:
        mem_mb=lambda wildcards: int(200000 * memory_multiplier),
        time="60:00:00"
    benchmark:
        os.path.join(output_dir, "{sample}", "benchmark", "chr_{chromosome}", "graph_creation_benchmark.txt")
    container:
        "oras://registry.forge.inrae.fr/pangepop/mspangepop/msprime_box:latest"
    threads: 20
    group: "graph_creation_pipeline"
    priority: 7
    shell:
        """
        python3 workflow/scripts/graph_creation.py \
            --splited_fasta {input.split_fasta} \
            --augmented_traversal {input.augmented_traversal} \
            --output_file {output.gfa} \
            --sample {wildcards.sample} \
            --chromosome {wildcards.chromosome} \
            --recap_file {output.recap} \
            --variant_plot_dir {params.out_dir} \
            --fasta_folder {params.fasta_folder} \
            --threads {threads}
        """

# This merges the nodes that can be merged in the GFA file
rule gfa_merge:
    input:
        initial_gfa = rules.graph_creation.output.gfa
    output:
        polished_gfa = os.path.join(output_dir, "{sample}", graph, "chr_{chromosome}", "{sample}_chr_{chromosome}_graph.gfa"),
        polished_gfa_stats = os.path.join(output_dir, "{sample}", graph, "chr_{chromosome}", "{sample}_chr_{chromosome}_graph_stats.txt"),
        og_raw = temp(os.path.join(output_dir, "{sample}", temp_dir, "{sample}_chr_{chromosome}_raw.og")),
        og_unchoped = temp(os.path.join(output_dir, "{sample}", temp_dir, "{sample}_chr_{chromosome}_unchoped.og"))
    resources:
        mem_mb=lambda wildcards: int(200000 * memory_multiplier),
        time="60:00:00"
    benchmark:
        os.path.join(output_dir, "{sample}", "benchmark", "chr_{chromosome}", "gfa_merge_benchmark.txt")
    container:
        "docker://registry.forge.inrae.fr/pangepop/mspangepop/odgi:v0.9.2"
    threads: 20
    group: "graph_creation_pipeline"
    priority: 7
    shell:
        """
        echo "[gfa_merge] Starting to clean the GFA file using odgi"
        echo "[gfa_merge] Importing..."
        odgi build -g {input.initial_gfa} -o {output.og_raw} -O -t {threads} -P
        echo "\n[gfa_merge] Initial GFA state :" > {output.polished_gfa_stats}
        odgi stats -i {output.og_raw} -S -L -b -t {threads} -P >> {output.polished_gfa_stats}
        echo "[gfa_merge] Starting to unchop"
        odgi unchop -i {output.og_raw} -o {output.og_unchoped} -t {threads} -P
        echo "\n[gfa_merge] Final state" : >> {output.polished_gfa_stats}
        odgi stats -i {output.og_unchoped} -S -S -L -b -t {threads} -P >> {output.polished_gfa_stats}
        cat {output.polished_gfa_stats}
        echo "\n[gfa_merge] Saving final GFA"
        odgi view -i {output.og_unchoped} -t {threads} -g > {output.polished_gfa}
        echo "✅ Final GFA @ {output.polished_gfa}"
        """

onsuccess:
    print("✅ MSpangepop -> Workflow completed successfully")
    shell("date")

onerror: 
    print("❌ MSpangepop -> Workflow failed, check logs")
    shell("date")